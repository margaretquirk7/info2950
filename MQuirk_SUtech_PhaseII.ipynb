{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "954bdb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import duckdb, sqlalchemy\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a20eac",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7e95",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "In order to simplify the analysis process, we've added a column to each of the initial dataframes called \"Subject\" so that when we combine the dataframes, we can easily identify which data set and subject the information relates to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "af0791c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Margaret Quirk\\AppData\\Local\\Temp\\ipykernel_18428\\1485939667.py:2: DtypeWarning: Columns (9,15,17,19,21,27,29,31,33,35,37,39,41,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ithaca = pd.read_csv(\"Ithaca.csv\")\n",
      "C:\\Users\\Margaret Quirk\\AppData\\Local\\Temp\\ipykernel_18428\\1485939667.py:3: DtypeWarning: Columns (27,29,31,33,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  others = pd.read_csv(\"AdjacentCities.csv\")\n",
      "C:\\Users\\Margaret Quirk\\AppData\\Local\\Temp\\ipykernel_18428\\1485939667.py:4: DtypeWarning: Columns (7,9,11,13,15,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  west = pd.read_csv(\"Erie.csv\")\n"
     ]
    }
   ],
   "source": [
    "#read in csvs\n",
    "ithaca = pd.read_csv(\"Ithaca.csv\")\n",
    "others = pd.read_csv(\"AdjacentCities.csv\")\n",
    "west = pd.read_csv(\"Erie.csv\")\n",
    "#print(ithaca.head())\n",
    "#print(west.head())\n",
    "others = others.dropna(axis=0,subset=['STATION'])\n",
    "#print(others.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ac5b2e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['North' 'South' 'East']\n"
     ]
    }
   ],
   "source": [
    "#Add column to indicate location (relative to ithaca)\n",
    "ithaca[\"Location\"] = \"Central\"\n",
    "west['Location'] = \"West\"\n",
    "#print(others['NAME'].unique())\n",
    "locations = []\n",
    "for i in others['NAME']:\n",
    "    if \"WATERTOWN\" in i:\n",
    "        locations.append('North')\n",
    "    elif \"BLACK RIVER\" in i:\n",
    "        locations.append(\"North\")\n",
    "    elif \"ESPY\" in i:\n",
    "        locations.append(\"South\")\n",
    "    elif \"BLOOMSBURG\" in i:\n",
    "        locations.append(\"South\")\n",
    "    elif \"COBLESKILL\" in i:\n",
    "        locations.append(\"East\")\n",
    "    else:\n",
    "        locations.append('N/A')\n",
    "others['Location'] = locations\n",
    "print(others['Location'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7461bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns match: proceed\n"
     ]
    }
   ],
   "source": [
    "#Check all columns match before concatenation\n",
    "columns_to_keep = []\n",
    "\n",
    "for i in ithaca.columns.tolist():\n",
    "    if (i in others.columns.tolist()) & (i in west.columns.tolist()) :\n",
    "        columns_to_keep.append(i)\n",
    "ithaca_good = ithaca[columns_to_keep]\n",
    "others_good = others[columns_to_keep]\n",
    "west_good = west[columns_to_keep]\n",
    "        \n",
    "if (ithaca_good.columns.tolist() == others_good.columns.tolist()) & (ithaca_good.columns.tolist() == west_good.columns.tolist()):\n",
    "    print(\"Columns match: proceed\")\n",
    "    final_df = pd.concat([ithaca_good,others_good,west_good])\n",
    "else:\n",
    "    print(ithaca.columns)\n",
    "    print(others.columns)\n",
    "    \n",
    "#print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc41c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'DAPR',\n",
      "       'DAPR_ATTRIBUTES', 'MDPR', 'MDPR_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES',\n",
      "       'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TMAX',\n",
      "       'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES',\n",
      "       'WESF', 'WESF_ATTRIBUTES', 'WT05', 'WT05_ATTRIBUTES', 'Location'],\n",
      "      dtype='object')\n",
      "No null columns\n"
     ]
    }
   ],
   "source": [
    "#Check for null values in columns\n",
    "print(final_df.columns)\n",
    "#If a column has only null values, drop the column\n",
    "null_cols = []\n",
    "for c in final_df.columns:\n",
    "    if final_df[c].isnull().all():\n",
    "        null_cols.append(c)\n",
    "if len(null_cols) == 0:\n",
    "    print(\"No null columns\")\n",
    "else:\n",
    "    print('Null columns:', null_cols)\n",
    "    final_df = final_df.drop(null_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7c2126e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary columns to indicate if there was trace of precipitation for snow and rain\n",
    "precip_binary = []\n",
    "snow_binary = []\n",
    "for p in final_df['PRCP_ATTRIBUTES']:\n",
    "    #print(type(p))\n",
    "    if (type(p) == str):\n",
    "        if 'T' in p:\n",
    "            precip_binary.append(1)\n",
    "        else:\n",
    "            precip_binary.append(0)\n",
    "    else:\n",
    "        precip_binary.append(0)\n",
    "        \n",
    "for s in final_df['SNOW_ATTRIBUTES']:\n",
    "    if (type(s) == str):\n",
    "        if 'T' in s:\n",
    "            snow_binary.append(1)\n",
    "        else:\n",
    "            snow_binary.append(0)\n",
    "    else:\n",
    "        snow_binary.append(0)\n",
    "    \n",
    "final_df['Precip Trace'] = precip_binary\n",
    "final_df['Snow Trace'] = snow_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f88fab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop attributes columns now that we have created the binary columns\n",
    "final_df = final_df.drop(columns = ['PRCP_ATTRIBUTES', 'SNOW_ATTRIBUTES'])\n",
    "#print(final_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6204f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 5 separate data frames based on location for individual analyses when needed\n",
    "central = final_df[final_df['Location']==\"Central\"]\n",
    "north = final_df[final_df['Location']==\"North\"]\n",
    "south = final_df[final_df['Location']==\"South\"]\n",
    "east = final_df[final_df['Location']==\"East\"]\n",
    "west = final_df[final_df['Location']==\"West\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6899a5",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b3bb6",
   "metadata": {},
   "source": [
    "## Data Limitations\n",
    "\n",
    "No student ids - can't link individual students between datasets\n",
    "\n",
    "Family size column is vague (over or under 3 people)\n",
    "\n",
    "Several columns are ranges from 1-5 with little detail on how students were placed within these categories. \n",
    "\n",
    "In the failures column, if a student has failed more than 3 classes in the past, the value listed is 4 regardless of how many they've failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2b959",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c518b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2343aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#side by side linear regression of consumption vs grades for math and portuguese sets\n",
    "#histogram for grades/consumption/absences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
